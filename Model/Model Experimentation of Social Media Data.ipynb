{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "564c8679-5fe2-4e96-98bd-5e77fb220c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphviz in /opt/homebrew/lib/python3.11/site-packages (0.20.1)\n",
      "Requirement already satisfied: anytree in /opt/homebrew/lib/python3.11/site-packages (2.8.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/rheagupta/Library/Python/3.11/lib/python/site-packages (from anytree) (1.16.0)\n",
      "Requirement already satisfied: transformers in /opt/homebrew/lib/python3.11/site-packages (4.27.4)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.11/site-packages (from transformers) (3.11.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/homebrew/lib/python3.11/site-packages (from transformers) (0.13.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/homebrew/lib/python3.11/site-packages (from transformers) (1.24.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/rheagupta/Library/Python/3.11/lib/python/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/rheagupta/Library/Python/3.11/lib/python/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/homebrew/lib/python3.11/site-packages (from transformers) (2023.3.23)\n",
      "Requirement already satisfied: requests in /opt/homebrew/lib/python3.11/site-packages (from transformers) (2.28.2)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/homebrew/lib/python3.11/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/homebrew/lib/python3.11/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.11/site-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rheagupta/Library/Python/3.11/lib/python/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/homebrew/lib/python3.11/site-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.11/site-packages (from requests->transformers) (2022.12.7)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install graphviz\n",
    "!pip3 install anytree\n",
    "!pip3 install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acf2fb58",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'graphviz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BertTokenizer, TFBertForSequenceClassification, InputExample, InputFeatures\n",
      "File \u001b[0;32m~/Desktop/FYP/Code/Confirmation-Bias-Model/functions.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01manytree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Node, RenderTree, search\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01manytree\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexporter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DotExporter\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgraphviz\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Source\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvaderSentiment\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvaderSentiment\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentimentIntensityAnalyzer\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'graphviz'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "from functions import *\n",
    "\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification, InputExample, InputFeatures\n",
    "\n",
    "from anytree import Node, RenderTree, search\n",
    "from anytree.exporter import DotExporter\n",
    "from graphviz import Source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1bb91a",
   "metadata": {},
   "source": [
    "# Load Subjectivity Detection Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b42e561",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at saved_subjectivity_model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('subjectivity_tokenizer')\n",
    "model = TFBertForSequenceClassification.from_pretrained('saved_subjectivity_model')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f508cf",
   "metadata": {},
   "source": [
    "# Read the dataset of comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a40e5e3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_name</th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>reply_to</th>\n",
       "      <th>comment</th>\n",
       "      <th>url</th>\n",
       "      <th>link_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MapleViolet</td>\n",
       "      <td>hpr2kav</td>\n",
       "      <td>2021-12-24 08:55:24</td>\n",
       "      <td>rmqevj</td>\n",
       "      <td>All I know is - anyone trying to pull a fast o...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HaddockFillet</td>\n",
       "      <td>hra9zzo</td>\n",
       "      <td>2022-01-05 08:14:35</td>\n",
       "      <td>hpr2kav</td>\n",
       "      <td>Why does she think it is OK to lie about such ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>applescript16</td>\n",
       "      <td>hpntm2t</td>\n",
       "      <td>2021-12-23 16:24:16</td>\n",
       "      <td>rmqevj</td>\n",
       "      <td>Here’s some perspective: \\n\\n1) The public nat...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iluj13</td>\n",
       "      <td>hpnwekg</td>\n",
       "      <td>2021-12-23 17:01:54</td>\n",
       "      <td>hpntm2t</td>\n",
       "      <td>Well said. It’s only a problem if your party i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>forzenrose</td>\n",
       "      <td>hpnzb4r</td>\n",
       "      <td>2021-12-23 17:41:51</td>\n",
       "      <td>hpnwekg</td>\n",
       "      <td>&amp;gt;Transparency and finding out the truth is ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_name       id            timestamp reply_to  \\\n",
       "0    MapleViolet  hpr2kav  2021-12-24 08:55:24   rmqevj   \n",
       "1  HaddockFillet  hra9zzo  2022-01-05 08:14:35  hpr2kav   \n",
       "2  applescript16  hpntm2t  2021-12-23 16:24:16   rmqevj   \n",
       "3         iluj13  hpnwekg  2021-12-23 17:01:54  hpntm2t   \n",
       "4     forzenrose  hpnzb4r  2021-12-23 17:41:51  hpnwekg   \n",
       "\n",
       "                                             comment  url link_title  \n",
       "0  All I know is - anyone trying to pull a fast o...  NaN        NaN  \n",
       "1  Why does she think it is OK to lie about such ...  NaN        NaN  \n",
       "2  Here’s some perspective: \\n\\n1) The public nat...  NaN        NaN  \n",
       "3  Well said. It’s only a problem if your party i...  NaN        NaN  \n",
       "4  &gt;Transparency and finding out the truth is ...  NaN        NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Datasets/reddit_data.csv', dtype=object)\n",
    "df['id'] = df['id'].astype(str)\n",
    "df['reply_to'] = df['reply_to'].astype(str)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe38cfd0",
   "metadata": {},
   "source": [
    "# Construct tree of Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8da8a813",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parent = 'rmqevj'\n",
    "root = Node(parent)\n",
    "\n",
    "input_list = [] \n",
    "item_count = df['reply_to'].value_counts().to_dict()\n",
    "\n",
    "for i in range(len(df['id'].tolist())):\n",
    "    if df['id'].loc[i] != df['reply_to'].loc[i]:\n",
    "        input_list.append((df['id'].loc[i], df['reply_to'].loc[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9023bd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict = make_map(input_list)\n",
    "createTree(output_dict[parent], root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fe924f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmqevj\n",
      "├── hpr2kav\n",
      "│   └── hra9zzo\n",
      "├── hpntm2t\n",
      "│   ├── hpnwekg\n",
      "│   │   ├── hpnzb4r\n",
      "│   │   │   └── hpo5qkg\n",
      "│   │   │       └── hpokj06\n",
      "│   │   │           ├── hpp0qgm\n",
      "│   │   │           ├── hpoqxz5\n",
      "│   │   │           └── hpraj0s\n",
      "│   │   │               └── hpshgjh\n",
      "│   │   ├── hpo2pl5\n",
      "│   │   │   └── hpo7oxl\n",
      "│   │   │       └── hpo7u0x\n",
      "│   │   ├── hpo76sq\n",
      "│   │   ├── hpo7l9d\n",
      "│   │   ├── hpradku\n",
      "│   │   │   ├── hps0rop\n",
      "│   │   │   └── hprqpon\n",
      "│   │   ├── hpoya8b\n",
      "│   │   └── hpnwve6\n",
      "│   │       └── hpnz3vc\n",
      "│   │           ├── hpp0vzg\n",
      "│   │           └── hpo6fwl\n",
      "│   │               └── hpp7l4j\n",
      "│   ├── hpo1src\n",
      "│   │   ├── hpolpfk\n",
      "│   │   ├── hpo33t8\n",
      "│   │   │   ├── hpo4que\n",
      "│   │   │   │   └── hpom3uq\n",
      "│   │   │   │       └── hprayhb\n",
      "│   │   │   │           └── hpruuh0\n",
      "│   │   │   └── hpoq8hi\n",
      "│   │   │       └── hppkszp\n",
      "│   │   │           └── hpppv0m\n",
      "│   │   └── hpo6898\n",
      "│   │       └── hpshl11\n",
      "│   ├── hpnx97j\n",
      "│   │   ├── hpnxtjg\n",
      "│   │   │   ├── hpo0tg0\n",
      "│   │   │   │   ├── hpo1tc3\n",
      "│   │   │   │   └── hprbgi9\n",
      "│   │   │   └── hpo2f3y\n",
      "│   │   ├── hpo0vbg\n",
      "│   │   ├── hpo3u4h\n",
      "│   │   │   └── hprbk9p\n",
      "│   │   ├── hpo2sxw\n",
      "│   │   │   └── hpo3zx7\n",
      "│   │   │       └── hpo8lmg\n",
      "│   │   │           ├── hpoc9nq\n",
      "│   │   │           │   └── hpocieg\n",
      "│   │   │           │       └── hpod1tg\n",
      "│   │   │           │           └── hpodjie\n",
      "│   │   │           └── hpo9x2u\n",
      "│   │   │               └── hpoajil\n",
      "│   │   │                   └── hpobclo\n",
      "│   │   │                       ├── hpoh7vc\n",
      "│   │   │                       │   └── hpoic96\n",
      "│   │   │                       └── hpobl51\n",
      "│   │   │                           └── hpocc0d\n",
      "│   │   ├── hpny4e7\n",
      "│   │   │   └── hpo7bug\n",
      "│   │   │       └── hpoxq4t\n",
      "│   │   ├── hps99uq\n",
      "│   │   ├── hpo1g5i\n",
      "│   │   ├── hpo1gqh\n",
      "│   │   ├── hpq0bex\n",
      "│   │   └── hpnxwuw\n",
      "│   │       └── hpnyqy2\n",
      "│   ├── hpo5ngp\n",
      "│   └── hpom4we\n",
      "├── hpob7bq\n",
      "│   ├── hpprwf1\n",
      "│   │   └── hprs02i\n",
      "│   └── hpr7oz0\n",
      "│       └── hpry51w\n",
      "├── hpof1j6\n",
      "├── hpo0saq\n",
      "│   ├── hpo6gzo\n",
      "│   │   └── hpo7amh\n",
      "│   └── hpo27so\n",
      "│       ├── hpo3fzb\n",
      "│       │   ├── hpodsd3\n",
      "│       │   │   └── hpoxxsw\n",
      "│       │   │       └── hpqw2cz\n",
      "│       │   │           └── hpr4wlz\n",
      "│       │   └── hpohy58\n",
      "│       └── hpo6lcp\n",
      "│           └── hpouq0j\n",
      "├── hpo3cmz\n",
      "│   └── hpo6o23\n",
      "├── hpnyjvo\n",
      "├── hpnvt4w\n",
      "│   └── hppsyl6\n",
      "│       └── hprp2gi\n",
      "├── hpo0qih\n",
      "│   └── hpobuiq\n",
      "│       └── hpoeyqv\n",
      "│           └── hpofw9d\n",
      "├── hpnzsws\n",
      "├── hpnyjtz\n",
      "│   ├── hpo4c81\n",
      "│   │   └── hpo4w1h\n",
      "│   └── hpo4yov\n",
      "├── hpo533h\n",
      "├── hpra194\n",
      "├── hpre7o3\n",
      "├── hpnrdc7\n",
      "│   └── hpnrgoq\n",
      "│       ├── hpnruey\n",
      "│       └── hpnrqek\n",
      "│           └── hpnvdd6\n",
      "├── hpo6q22\n",
      "├── hpon121\n",
      "├── hpnr9fl\n",
      "│   ├── hpo4k7u\n",
      "│   │   └── hpo6alz\n",
      "│   ├── hpnutru\n",
      "│   │   ├── hpnw22i\n",
      "│   │   └── hpr00cm\n",
      "│   └── hpnu57s\n",
      "│       ├── hpnw795\n",
      "│       ├── hpo3pca\n",
      "│       ├── hpnvyi4\n",
      "│       └── hpnucm4\n",
      "├── hpnw84k\n",
      "│   └── hpo4anc\n",
      "│       └── hpo56mt\n",
      "├── hpodljr\n",
      "├── hpozmnv\n",
      "├── hpnryzo\n",
      "│   ├── hpnu97n\n",
      "│   │   └── hpnv1rw\n",
      "│   ├── hpnuz6a\n",
      "│   │   └── hppa16y\n",
      "│   ├── hpnxn2r\n",
      "│   ├── hpnuf2x\n",
      "│   └── hpogjxd\n",
      "│       └── hpoopqq\n",
      "├── hpnrzkf\n",
      "│   ├── hprnyx8\n",
      "│   ├── hpnsk7p\n",
      "│   │   ├── hpny4vs\n",
      "│   │   └── hpnwvjk\n",
      "│   └── hpnw68t\n",
      "├── hpnyz39\n",
      "├── hpoafhh\n",
      "│   ├── hprle0j\n",
      "│   └── hppv9c0\n",
      "├── hpnsbx9\n",
      "│   ├── hprcrot\n",
      "│   │   └── hprheru\n",
      "│   │       └── hpriq0m\n",
      "│   └── hpnt561\n",
      "│       ├── hpnve6g\n",
      "│       └── hpnwvga\n",
      "├── hpnxruu\n",
      "│   └── hpo4g5j\n",
      "├── hpofz3r\n",
      "├── hprrd72\n",
      "├── hppcalj\n",
      "│   └── hpr0jzr\n",
      "│       └── hpr4rhs\n",
      "├── hpqk0v9\n",
      "├── hpoi306\n",
      "│   └── hpolg78\n",
      "├── hpofvms\n",
      "├── hpo3p8n\n",
      "├── hps2r4o\n",
      "├── hpr7hra\n",
      "├── hpph5n4\n",
      "├── hpoq4cz\n",
      "├── hpnxb94\n",
      "│   └── hpo4i3n\n",
      "├── hpo24t2\n",
      "├── hpnt6fy\n",
      "├── hpr9xwq\n",
      "├── hpobx5f\n",
      "├── hpr73zc\n",
      "├── hpp9czp\n",
      "└── hpnw8qy\n"
     ]
    }
   ],
   "source": [
    "printGraph(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592ff039",
   "metadata": {},
   "source": [
    "# Predict the results of sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa20f971",
   "metadata": {},
   "source": [
    "Lexicon-based approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bc88246",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_sentences = cleanComments(df['comment'])\n",
    "\n",
    "textblob_polarity = []\n",
    "textblob_subjectivity = []\n",
    "vader_results = []\n",
    "vaderCompoundScores = []\n",
    "\n",
    "for i in pred_sentences:\n",
    "    result = getSentimentalResults(sid_obj, i)\n",
    "    textblob_polarity.append(result[0])\n",
    "    textblob_subjectivity.append(result[1])\n",
    "    vader_results.append(result[2])\n",
    "    vaderCompoundScores.append(result[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4978f11",
   "metadata": {},
   "source": [
    "Supervised learning approach through BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64bcbb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_batch = tokenizer(pred_sentences, max_length=128, padding=True, truncation=True, return_tensors='tf')\n",
    "tf_outputs = model(tf_batch)\n",
    "tf_predictions = tf.nn.softmax(tf_outputs[0], axis=-1)\n",
    "\n",
    "labels = [0,1]\n",
    "label = tf.argmax(tf_predictions, axis=1)\n",
    "label = label.numpy()\n",
    "\n",
    "result = []\n",
    "\n",
    "for i in range(len(pred_sentences)):\n",
    "    result.append(float(tf_predictions[i,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a4169b",
   "metadata": {},
   "source": [
    "Implement text clustering and save all results into a structured dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e7b3c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tkjie\\anaconda3\\envs\\venv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1332: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_name</th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>reply_to</th>\n",
       "      <th>comment</th>\n",
       "      <th>url</th>\n",
       "      <th>link_title</th>\n",
       "      <th>textblob_polarity</th>\n",
       "      <th>textblob_subjectivity</th>\n",
       "      <th>vader_sentiment</th>\n",
       "      <th>vader_compound_score</th>\n",
       "      <th>model_subjectivity</th>\n",
       "      <th>topic_cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MapleViolet</td>\n",
       "      <td>hpr2kav</td>\n",
       "      <td>2021-12-24 08:55:24</td>\n",
       "      <td>rmqevj</td>\n",
       "      <td>All I know is - anyone trying to pull a fast o...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.500000e-01</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.912, 'pos': 0.088}</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>0.998633</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HaddockFillet</td>\n",
       "      <td>hra9zzo</td>\n",
       "      <td>2022-01-05 08:14:35</td>\n",
       "      <td>hpr2kav</td>\n",
       "      <td>Why does she think it is OK to lie about such ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.500000e-01</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.827, 'pos': 0.173}</td>\n",
       "      <td>0.4466</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>applescript16</td>\n",
       "      <td>hpntm2t</td>\n",
       "      <td>2021-12-23 16:24:16</td>\n",
       "      <td>rmqevj</td>\n",
       "      <td>Here’s some perspective: \\n\\n1) The public nat...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.214286e-02</td>\n",
       "      <td>0.388095</td>\n",
       "      <td>{'neg': 0.05, 'neu': 0.828, 'pos': 0.122}</td>\n",
       "      <td>0.8519</td>\n",
       "      <td>0.829385</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iluj13</td>\n",
       "      <td>hpnwekg</td>\n",
       "      <td>2021-12-23 17:01:54</td>\n",
       "      <td>hpntm2t</td>\n",
       "      <td>Well said. It’s only a problem if your party i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.142857e-01</td>\n",
       "      <td>0.736508</td>\n",
       "      <td>{'neg': 0.136, 'neu': 0.673, 'pos': 0.191}</td>\n",
       "      <td>0.2263</td>\n",
       "      <td>0.700985</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>forzenrose</td>\n",
       "      <td>hpnzb4r</td>\n",
       "      <td>2021-12-23 17:41:51</td>\n",
       "      <td>hpnwekg</td>\n",
       "      <td>&amp;gt;Transparency and finding out the truth is ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.700743e-17</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>{'neg': 0.192, 'neu': 0.603, 'pos': 0.205}</td>\n",
       "      <td>-0.1280</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_name       id            timestamp reply_to  \\\n",
       "0    MapleViolet  hpr2kav  2021-12-24 08:55:24   rmqevj   \n",
       "1  HaddockFillet  hra9zzo  2022-01-05 08:14:35  hpr2kav   \n",
       "2  applescript16  hpntm2t  2021-12-23 16:24:16   rmqevj   \n",
       "3         iluj13  hpnwekg  2021-12-23 17:01:54  hpntm2t   \n",
       "4     forzenrose  hpnzb4r  2021-12-23 17:41:51  hpnwekg   \n",
       "\n",
       "                                             comment  url link_title  \\\n",
       "0  All I know is - anyone trying to pull a fast o...  NaN        NaN   \n",
       "1  Why does she think it is OK to lie about such ...  NaN        NaN   \n",
       "2  Here’s some perspective: \\n\\n1) The public nat...  NaN        NaN   \n",
       "3  Well said. It’s only a problem if your party i...  NaN        NaN   \n",
       "4  &gt;Transparency and finding out the truth is ...  NaN        NaN   \n",
       "\n",
       "   textblob_polarity  textblob_subjectivity  \\\n",
       "0       4.500000e-01               0.600000   \n",
       "1       2.500000e-01               0.500000   \n",
       "2       8.214286e-02               0.388095   \n",
       "3       2.142857e-01               0.736508   \n",
       "4       3.700743e-17               0.755556   \n",
       "\n",
       "                              vader_sentiment  vader_compound_score  \\\n",
       "0    {'neg': 0.0, 'neu': 0.912, 'pos': 0.088}                0.4404   \n",
       "1    {'neg': 0.0, 'neu': 0.827, 'pos': 0.173}                0.4466   \n",
       "2   {'neg': 0.05, 'neu': 0.828, 'pos': 0.122}                0.8519   \n",
       "3  {'neg': 0.136, 'neu': 0.673, 'pos': 0.191}                0.2263   \n",
       "4  {'neg': 0.192, 'neu': 0.603, 'pos': 0.205}               -0.1280   \n",
       "\n",
       "   model_subjectivity  topic_cluster  \n",
       "0            0.998633              1  \n",
       "1            0.000084              0  \n",
       "2            0.829385              0  \n",
       "3            0.700985              0  \n",
       "4            0.000424              0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['textblob_polarity'] = textblob_polarity\n",
    "df['textblob_subjectivity'] = textblob_subjectivity\n",
    "df['vader_sentiment'] = vader_results\n",
    "df['vader_compound_score'] = vaderCompoundScores\n",
    "df['model_subjectivity'] = result\n",
    "df['topic_cluster'] = getClusters(pred_sentences, embedder)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b41c76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
